# lr
基于LR的优化方法：梯度下降法，随机梯度下降法，牛顿法，LBFGS，BFGS
是梯度下降还是梯度上升取决于求最大值还是最小值，而且要确保函数是凸的或者凹的。这样才能保证收敛到全局最优点。
梯度下降法所需要的alpha即步长是要改变的，而且有两种方法去提高：一种把特征进行归一化，这样收敛比较快，另一种是随着越接近真值越要改变步长。步长要越小。
4.牛顿下降法可应用于多个方面，比如sqrt函数的求解。但牛顿法在计算多维变量的时候出现的海森矩阵是个大问题，即二阶导数。因此需要估计。
5.
